{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12702199,"sourceType":"datasetVersion","datasetId":8027711}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:09:22.589020Z","iopub.execute_input":"2025-08-07T15:09:22.589722Z","iopub.status.idle":"2025-08-07T15:09:22.598255Z","shell.execute_reply.started":"2025-08-07T15:09:22.589699Z","shell.execute_reply":"2025-08-07T15:09:22.597665Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/toxicity-detection/val.csv\n/kaggle/input/toxicity-detection/train.csv\n/kaggle/input/toxicity-detection/test.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# Load your data\ntrain_df = pd.read_csv(\"/kaggle/input/toxicity-detection/train.csv\")\nval_df = pd.read_csv(\"/kaggle/input/toxicity-detection/val.csv\")\n\n# Rename target column for Trainer\ntrain_df = train_df.rename(columns={\"toxic\": \"label\"})\nval_df = val_df.rename(columns={\"toxic\": \"label\"})\n\n# Convert to Hugging Face datasets\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T16:58:47.355745Z","iopub.execute_input":"2025-08-07T16:58:47.356015Z","iopub.status.idle":"2025-08-07T16:58:48.876306Z","shell.execute_reply.started":"2025-08-07T16:58:47.355993Z","shell.execute_reply":"2025-08-07T16:58:48.875536Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"comment_text\"], padding=\"max_length\", truncation=True, max_length=512)\n\ntrain_ds = train_ds.map(tokenize, batched=True)\nval_ds = val_ds.map(tokenize, batched=True)\n\ntrain_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\nval_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:10:40.483283Z","iopub.execute_input":"2025-08-07T15:10:40.483538Z","iopub.status.idle":"2025-08-07T15:11:35.734963Z","shell.execute_reply.started":"2025-08-07T15:10:40.483520Z","shell.execute_reply":"2025-08-07T15:11:35.734366Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5caffe430ea248508c057576ca8297ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c9129e8d57a44c6b32d626cb7e653fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be80861936524ebba9225d1ee9c2a2af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825e553123bb4ef9b727e2126a8e4066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eeeeb3ffd0a4c42878312626d455e09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/125696 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf0f8a9e5fc4e1293d0640f1249ab66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/26935 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a57994454884031a4704434715d0a5c"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification\nfrom torch.nn import BCEWithLogitsLoss\nimport torch\n\n# Compute class weights (inverse frequency)\nnum_pos = train_df[\"label\"].sum()\nnum_neg = len(train_df) - num_pos\nweight = torch.tensor([num_neg / num_pos], dtype=torch.float)\n\n# Custom model with weighted loss\nclass RobertaForToxicClassification(RobertaForSequenceClassification):\n    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n        kwargs.pop(\"num_items_in_batch\", None)\n        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, labels=None, **kwargs)\n        logits = outputs.logits\n\n        if labels is not None:\n            loss_fct = BCEWithLogitsLoss(pos_weight=weight.to(logits.device))\n            labels = labels.unsqueeze(1).float()  # shape: [batch_size, 1]\n            loss = loss_fct(logits, labels)\n            return {\"loss\": loss, \"logits\": logits}\n        else:\n            return {\"logits\": logits}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:23:57.900526Z","iopub.execute_input":"2025-08-07T15:23:57.901197Z","iopub.status.idle":"2025-08-07T15:23:57.909854Z","shell.execute_reply.started":"2025-08-07T15:23:57.901168Z","shell.execute_reply":"2025-08-07T15:23:57.908968Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\n\ndef compute_metrics(p):\n    preds = torch.sigmoid(torch.tensor(p.predictions)).numpy() > 0.5\n    labels = p.label_ids\n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"precision\": precision_score(labels, preds, zero_division=0),\n        \"recall\": recall_score(labels, preds, zero_division=0),\n        \"f1\": f1_score(labels, preds, zero_division=0)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:14:03.183154Z","iopub.execute_input":"2025-08-07T15:14:03.184071Z","iopub.status.idle":"2025-08-07T15:14:03.188683Z","shell.execute_reply.started":"2025-08-07T15:14:03.184046Z","shell.execute_reply":"2025-08-07T15:14:03.187799Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nmodel = RobertaForToxicClassification.from_pretrained(\"roberta-base\", num_labels=1)\ntrain_ds_small = train_ds.shuffle(seed=42).select(range(len(train_ds) // 5))\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=16,         \n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=2, \n    num_train_epochs=3,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    fp16=True,                              \n    report_to=\"none\"                        \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds_small,\n    eval_dataset=val_ds,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T15:32:31.109828Z","iopub.execute_input":"2025-08-07T15:32:31.110310Z","iopub.status.idle":"2025-08-07T16:55:09.394538Z","shell.execute_reply.started":"2025-08-07T15:32:31.110287Z","shell.execute_reply":"2025-08-07T16:55:09.393804Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForToxicClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2358' max='2358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2358/2358 1:22:35, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.127200</td>\n      <td>0.543705</td>\n      <td>0.964210</td>\n      <td>0.819318</td>\n      <td>0.816226</td>\n      <td>0.817769</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.906200</td>\n      <td>0.588877</td>\n      <td>0.963542</td>\n      <td>0.799139</td>\n      <td>0.840755</td>\n      <td>0.819419</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.656100</td>\n      <td>0.735586</td>\n      <td>0.964878</td>\n      <td>0.808249</td>\n      <td>0.843019</td>\n      <td>0.825268</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2358, training_loss=0.896513624247906, metrics={'train_runtime': 4956.8443, 'train_samples_per_second': 15.215, 'train_steps_per_second': 0.476, 'total_flos': 1.9842868299377664e+16, 'train_loss': 0.896513624247906, 'epoch': 3.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/toxicity-detection/test.csv\")\ntest_df = test_df.rename(columns={\"toxic\": \"label\"})\ntest_ds = Dataset.from_pandas(test_df)\ntest_ds = test_ds.map(tokenize, batched=True)\ntest_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:00:07.673067Z","iopub.execute_input":"2025-08-07T17:00:07.673890Z","iopub.status.idle":"2025-08-07T17:00:15.321095Z","shell.execute_reply.started":"2025-08-07T17:00:07.673859Z","shell.execute_reply":"2025-08-07T17:00:15.320513Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/26936 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2134dba4d964d81b216e1da52b1955c"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=test_ds)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:02:31.944222Z","iopub.execute_input":"2025-08-07T17:02:31.944880Z","iopub.status.idle":"2025-08-07T17:09:28.512021Z","shell.execute_reply.started":"2025-08-07T17:02:31.944858Z","shell.execute_reply":"2025-08-07T17:09:28.511402Z"}},"outputs":[{"name":"stdout","text":"{'eval_loss': 0.7270007729530334, 'eval_accuracy': 0.9652138402138403, 'eval_precision': 0.8099891422366993, 'eval_recall': 0.8445283018867924, 'eval_f1': 0.8268982080177352, 'eval_runtime': 416.5595, 'eval_samples_per_second': 64.663, 'eval_steps_per_second': 4.043, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer.save_model(\"./toxic_roberta_model\")  # Save model weights + config\ntokenizer.save_pretrained(\"./toxic_roberta_model\")  # Save tokenizer files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:13:46.987632Z","iopub.execute_input":"2025-08-07T17:13:46.988149Z","iopub.status.idle":"2025-08-07T17:13:47.861048Z","shell.execute_reply.started":"2025-08-07T17:13:46.988127Z","shell.execute_reply":"2025-08-07T17:13:47.860444Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('./toxic_roberta_model/tokenizer_config.json',\n './toxic_roberta_model/special_tokens_map.json',\n './toxic_roberta_model/vocab.json',\n './toxic_roberta_model/merges.txt',\n './toxic_roberta_model/added_tokens.json',\n './toxic_roberta_model/tokenizer.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"!zip -r toxic_roberta_model.zip ./toxic_roberta_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T17:23:56.230835Z","iopub.execute_input":"2025-08-07T17:23:56.231637Z","iopub.status.idle":"2025-08-07T17:24:23.971576Z","shell.execute_reply.started":"2025-08-07T17:23:56.231599Z","shell.execute_reply":"2025-08-07T17:24:23.970676Z"}},"outputs":[{"name":"stdout","text":"  adding: toxic_roberta_model/ (stored 0%)\n  adding: toxic_roberta_model/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: toxic_roberta_model/tokenizer.json (deflated 82%)\n  adding: toxic_roberta_model/vocab.json (deflated 59%)\n  adding: toxic_roberta_model/tokenizer_config.json (deflated 75%)\n  adding: toxic_roberta_model/training_args.bin (deflated 51%)\n  adding: toxic_roberta_model/special_tokens_map.json (deflated 52%)\n  adding: toxic_roberta_model/merges.txt (deflated 53%)\n  adding: toxic_roberta_model/config.json (deflated 50%)\n","output_type":"stream"}],"execution_count":26}]}